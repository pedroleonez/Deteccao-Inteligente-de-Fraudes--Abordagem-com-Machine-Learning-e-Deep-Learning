# Detec√ß√£o Inteligente de Fraudes: Abordagem com Machine Learning e Deep Learning

Este projeto consiste em um pipeline completo de ci√™ncia de dados para a detec√ß√£o de fraudes em transa√ß√µes de cart√µes de cr√©dito. O desafio central √© o desequil√≠brio extremo das classes, onde apenas **0,172%** das transa√ß√µes s√£o fraudulentas. A solu√ß√£o utiliza uma abordagem h√≠brida de **Ensemble Learning**, combinando **XGBoost** e **Redes Neurais**.

## üìä Vis√£o Geral do Projeto

A seguran√ßa financeira depende da identifica√ß√£o de anomalias em tempo real. Este projeto foca na maximiza√ß√£o do **AUPRC** (Area Under the Precision-Recall Curve) e do **F1-Score**, garantindo que o sistema seja seguro para a institui√ß√£o e fluido para o cliente leg√≠timo.

### üîó Base de Dados
O dataset utilizado cont√©m transa√ß√µes feitas por cart√µes de cr√©dito em setembro de 2013 por titulares europeus. Devido a quest√µes de confidencialidade, as vari√°veis passaram por uma transforma√ß√£o PCA.
- **Fonte:** [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

## üõ†Ô∏è Tecnologias e Ferramentas
- **Linguagem:** Python
- **Manipula√ß√£o e Visualiza√ß√£o:** Pandas, NumPy, Matplotlib, Seaborn
- **Machine Learning:** Scikit-learn, XGBoost
- **Deep Learning:** TensorFlow, Keras
- **Processamento de Dados Desbalanceados:** Imbalanced-learn (SMOTE)

## üöÄ Metodologia

### 1. Pr√©-processamento e Escalonamento
Para lidar com *outliers* e escalas distintas nas vari√°veis `Time` e `Amount`, foi utilizado o **RobustScaler**, que baseia o escalonamento na mediana e nos quartis.

### 2. Tratamento de Desbalanceamento
Utilizamos a t√©cnica **SMOTE** (*Synthetic Minority Over-sampling Technique*) apenas nos dados de treino para criar exemplos sint√©ticos da classe minorit√°ria, permitindo que o modelo aprenda os padr√µes de fraude sem "decorar" os dados originais.

### 3. Modelagem H√≠brida (Ensemble)
Foi implementado um **Ensemble de M√©dia Ponderada**:
- **XGBoost (Peso 0.4):** Excelente na captura de rela√ß√µes tabulares e intera√ß√µes complexas.
- **Rede Neural MLP (Peso 0.6):** Alta capacidade de processamento n√£o-linear e generaliza√ß√£o.

A probabilidade final √© calculada por:  
$$P_{\text{final}} = (P_{\text{XGBoost}} \times 0.4) + (P_{\text{RedeNeural}} \times 0.6)$$

### 4. Otimiza√ß√£o de Limiar (Threshold)
O limiar de decis√£o foi elevado para **0.7**, focando em aumentar a confian√ßa dos alertas e reduzir o n√∫mero de clientes leg√≠timos bloqueados injustamente.

## üìà Resultados e Impacto no Neg√≥cio

O modelo final atingiu m√©tricas de estado da arte para este dataset:

| M√©trica | Resultado |
| :--- | :--- |
| **Precis√£o** | 65% |
| **Recall (Sensibilidade)** | 86% |
| **F1-Score** | 0.74 |

### An√°lise de ROI (Retorno sobre Investimento)
Considerando premissas de mercado (R$ 500 de economia por fraude detectada e R$ 10 de custo por falso alarme):
- **Fraudes bloqueadas:** 84
- **Alarmes falsos:** 45
- **Economia L√≠quida Gerada: R$ 41.550,00**

O sistema demonstrou ser altamente lucrativo, onde a economia gerada supera em quase **100 vezes** os custos operacionais.

## üìã Como executar
1. Clone o reposit√≥rio.
2. Certifique-se de ter as bibliotecas instaladas:
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn xgboost tensorflow imbalanced-learn